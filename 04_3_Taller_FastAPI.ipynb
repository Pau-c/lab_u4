{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "99c51ec8",
      "metadata": {
        "id": "99c51ec8"
      },
      "source": [
        "\n",
        "# Taller (3h) — FastAPI + Scikit-Learn orientado a investigación\n",
        "**Objetivo:** Diseñar, entrenar y servir un modelo de ML **investigando** las decisiones técnicas clave.  \n",
        "**Entrega:** API funcional (FastAPI) + breve informe (markdown dentro del notebook) justificando decisiones.\n",
        "\n",
        "> Filosofía del taller: menos receta, más criterio. No hay una única respuesta correcta; lo evaluado es la **calidad del razonamiento**, la **limpieza de la implementación** y la **capacidad de probar** la API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdea1218",
      "metadata": {
        "id": "bdea1218"
      },
      "source": [
        "\n",
        "## Agenda sugerida (3h)\n",
        "1) **Planteo del problema y dataset** (30–40 min)  \n",
        "2) **Entrenamiento y persistencia** (40–50 min)  \n",
        "3) **Diseño del contrato y API** (45–55 min)  \n",
        "4) **Pruebas, errores y mejoras** (30–35 min)\n",
        "\n",
        "### Reglas\n",
        "- No borres los encabezados `TODO`. Agrega tu código debajo de cada bloque indicado.\n",
        "- Documenta tus decisiones en la sección **Bitácora** al final.\n",
        "- Puedes trabajar en equipo, pero cada entrega debe ser individual y original.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0cc07b6",
      "metadata": {
        "id": "e0cc07b6"
      },
      "source": [
        "\n",
        "---\n",
        "## 1) Selección de dataset y formulación del problema (investigación)\n",
        "Elige **uno**:\n",
        "- A) `sklearn.datasets.load_wine` (clasificación 3 clases, baseline rápido)\n",
        "- B) Un dataset tabular de UCI, Kaggle u otra fuente **citable** (debe ser pequeño/mediano y con licencia apta)\n",
        "- C) Un CSV propio (explica origen y variables)\n",
        "\n",
        "**Requisitos mínimos:**\n",
        "- Problema de **clasificación** o **regresión** tabular\n",
        "- Al menos **6 features numéricas** (puedes convertir categóricas)\n",
        "- Justifica por qué es un buen caso para servir vía API\n",
        "\n",
        "**Entrega (en esta celda, texto breve):** Describe el dataset, objetivo, variables y métrica principal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a51c33",
      "metadata": {
        "id": "15a51c33"
      },
      "source": [
        "\n",
        "### 1.1 Carga y exploración (TODO)\n",
        "- Carga el dataset (pd.read_csv o loader de sklearn).\n",
        "- Muestra `head()`, `describe()` y verifica nulos/outliers.\n",
        "- Selecciona `X` (features) y `y` (target); explica tu elección.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b92213bd",
      "metadata": {
        "id": "b92213bd"
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "Implementa la carga y exploración del dataset",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# from sklearn.datasets import load_wine\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Ejemplo de estructura (reemplaza con tu fuente):\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# df = pd.read_csv(\"TU_DATASET.csv\")\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ---- TU CÓDIGO AQUÍ ----\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mImplementa la carga y exploración del dataset\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNotImplementedError\u001b[39m: Implementa la carga y exploración del dataset"
          ]
        }
      ],
      "source": [
        "# TODO: Carga y EDA mínima\n",
        "import pandas as pd\n",
        "\n",
        "# from sklearn.datasets import load_wine\n",
        "\n",
        "# Ejemplo de estructura (reemplaza con tu fuente):\n",
        "# df = pd.read_csv(\"TU_DATASET.csv\")\n",
        "# ---- TU CÓDIGO AQUÍ ----\n",
        "raise NotImplementedError(\"Implementa la carga y exploración del dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "575da8f8",
      "metadata": {
        "id": "575da8f8"
      },
      "source": [
        "\n",
        "---\n",
        "## 2) Entrenamiento y persistencia del modelo (investigación)\n",
        "Toma decisiones y **justifícalas**:\n",
        "- ¿Modelo base? (p. ej. `LogisticRegression`, `RandomForest`, `XGBoost` si lo instalas)\n",
        "- ¿Preprocesamiento? (escala, imputación, OneHot, etc.)\n",
        "- ¿Validación? (`train_test_split` vs `cross_val_score`)\n",
        "- ¿Métrica? (clasificación: accuracy/F1; regresión: RMSE/MAE…)\n",
        "\n",
        "**Requisito:** empaqueta tu flujo en un `Pipeline` de sklearn y **persiste** el modelo y columnas (joblib + JSON).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6172f286",
      "metadata": {
        "id": "6172f286"
      },
      "outputs": [],
      "source": [
        "# TODO: split, pipeline, training, evaluación y persistencia\n",
        "from pathlib import Path\n",
        "import json, joblib\n",
        "\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")\n",
        "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Variables esperadas:\n",
        "# X, y = ...\n",
        "# pipeline = ...\n",
        "# métricas calculadas en 'metrics' (dict)\n",
        "\n",
        "# ---- TU CÓDIGO AQUÍ ----\n",
        "raise NotImplementedError(\"Implementa split, pipeline, entrenamiento y evaluación\")\n",
        "\n",
        "# TODO: Persistir\n",
        "# joblib.dump(pipeline, ARTIFACTS_DIR / \"model.joblib\")\n",
        "# json.dump({\"feature_columns\": list(X.columns)}, open(ARTIFACTS_DIR / \"feature_columns.json\", \"w\"))\n",
        "# json.dump({\"metrics\": metrics}, open(ARTIFACTS_DIR / \"metadata.json\", \"w\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c134dd",
      "metadata": {
        "id": "00c134dd"
      },
      "source": [
        "\n",
        "---\n",
        "## 3) Diseño del contrato de la API (investigación)\n",
        "Define **endpoints mínimos**:\n",
        "- `GET /health` (estado, versión del modelo, métrica)\n",
        "- `POST /predict` (un registro)\n",
        "- `POST /predict-batch` (lista de registros)\n",
        "\n",
        "**Decisiones a justificar:**\n",
        "- ¿Qué validaciones aplicas en `Pydantic`? (rango, tipos, campos extra)\n",
        "- ¿Cómo garantizas el **orden** de columnas?\n",
        "- ¿Qué devuelves además de la predicción? (probabilidades, latencia, advertencias)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf840dc",
      "metadata": {
        "id": "caf840dc"
      },
      "outputs": [],
      "source": [
        "# TODO: Generar un esquema dinámico a partir de las columnas persistidas (opcional pero recomendado)\n",
        "# Carga feature_columns.json y crea un dict para generar ejemplos de payload\n",
        "import json, os\n",
        "from pathlib import Path\n",
        "\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")\n",
        "feat_path = ARTIFACTS_DIR / \"feature_columns.json\"\n",
        "# ---- TU CÓDIGO AQUÍ ----\n",
        "raise NotImplementedError(\n",
        "    \"Construye un ejemplo de payload a partir de las columnas persistidas\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8abce9f",
      "metadata": {
        "id": "f8abce9f"
      },
      "source": [
        "\n",
        "---\n",
        "## 4) Implementación de FastAPI (investigación)\n",
        "Crea un archivo `app.py` con:\n",
        "- Carga perezosa de `model.joblib` y `feature_columns.json`\n",
        "- Esquemas Pydantic (v2)\n",
        "- Endpoints `/health`, `/predict`, `/predict-batch`\n",
        "- Manejo de errores con `HTTPException` y mensajes claros\n",
        "\n",
        "**Pistas** (no copiar/pegar sin entender):\n",
        "- `model = joblib.load(...)`\n",
        "- `class Sample(BaseModel): ...`\n",
        "- `model.predict` y/o `model.predict_proba`\n",
        "- Retornar JSON con `dict | BaseModel`\n",
        "\n",
        "**Requisito:** esta celda **debe** escribir `app.py` con al menos la estructura básica.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c41fccc6",
      "metadata": {
        "id": "c41fccc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'app.py escrito (plantilla con TODOs)'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Escribir app.py\n",
        "from textwrap import dedent\n",
        "from pathlib import Path\n",
        "\n",
        "app_code = dedent(\n",
        "    \"\"\"\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel, ConfigDict, Field\n",
        "from typing import List, Dict\n",
        "import joblib, json, time\n",
        "from pathlib import Path\n",
        "\n",
        "APP_VERSION = \"0.1.0\"\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")\n",
        "MODEL_PATH = ARTIFACTS_DIR / \"model.joblib\"\n",
        "COLUMNS_PATH = ARTIFACTS_DIR / \"feature_columns.json\"\n",
        "META_PATH = ARTIFACTS_DIR / \"metadata.json\"\n",
        "\n",
        "app = FastAPI(title=\"ML API\", version=APP_VERSION)\n",
        "\n",
        "# TODO: Define tus modelos Pydantic aquí\n",
        "class Sample(BaseModel):\n",
        "    model_config = ConfigDict(extra=\"forbid\")\n",
        "    # ---- COMPLETA CON TUS CAMPOS SEGÚN feature_columns.json ----\n",
        "    # ejemplo: feature_x: float = Field(..., ge=0)\n",
        "\n",
        "class PredictionOut(BaseModel):\n",
        "    # ---- COMPLETA: qué devuelves? label / score / probs / latencia ----\n",
        "    pass\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_artifacts():\n",
        "    global model, columns, meta\n",
        "    if not MODEL_PATH.exists():\n",
        "        raise RuntimeError(\"Modelo no encontrado. Entrena y exporta primero.\")\n",
        "    model = joblib.load(MODEL_PATH)\n",
        "    columns = json.loads(COLUMNS_PATH.read_text())[\"feature_columns\"]\n",
        "    meta = json.loads(META_PATH.read_text()) if META_PATH.exists() else {}\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\n",
        "        \"status\": \"ok\",\n",
        "        \"version\": APP_VERSION,\n",
        "        \"metrics\": meta.get(\"metrics\"),\n",
        "        \"n_features\": len(columns)\n",
        "    }\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(sample: Sample):\n",
        "    try:\n",
        "        start = time.perf_counter()\n",
        "        # TODO: transforma 'sample' a lista en el orden de 'columns'\n",
        "        # y haz model.predict / predict_proba\n",
        "        # ---- TU CÓDIGO AQUÍ ----\n",
        "        raise NotImplementedError\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=str(e))\n",
        "\n",
        "@app.post(\"/predict-batch\")\n",
        "def predict_batch(samples: List[Sample]):\n",
        "    try:\n",
        "        # TODO: similar a /predict pero para lista\n",
        "        # ---- TU CÓDIGO AQUÍ ----\n",
        "        raise NotImplementedError\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=str(e))\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "Path(\"app.py\").write_text(app_code)\n",
        "\"app.py escrito (plantilla con TODOs)\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3effd9b0",
      "metadata": {
        "id": "3effd9b0"
      },
      "source": [
        "\n",
        "### 4.1 Ejecutar el servidor\n",
        "```bash\n",
        "uvicorn app:app --reload --port 8000\n",
        "```\n",
        "Abre `http://127.0.0.1:8000/docs` y prueba manualmente. Registra resultados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59771f1d",
      "metadata": {
        "id": "59771f1d"
      },
      "source": [
        "\n",
        "---\n",
        "## 5) Pruebas y casos límite (investigación)\n",
        "Define y ejecuta **al menos 6** pruebas:\n",
        "- 3 válidas (predict y batch)\n",
        "- 3 inválidas (campo faltante, tipo incorrecto, campo extra, etc.)\n",
        "\n",
        "Incluye código de prueba y captura de respuestas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc5c4f6",
      "metadata": {
        "id": "cbc5c4f6"
      },
      "outputs": [],
      "source": [
        "# TODO: pruebas con requests (server debe estar corriendo)\n",
        "# import requests, json\n",
        "# payload_valido = {...}\n",
        "# r = requests.post(\"http://127.0.0.1:8000/predict\", json=payload_valido, timeout=5)\n",
        "# print(r.status_code, r.json())\n",
        "raise NotImplementedError(\"Escribe tus pruebas de cliente aquí\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "662bd072",
      "metadata": {
        "id": "662bd072"
      },
      "source": [
        "\n",
        "---\n",
        "## 6) (Opcional) Observabilidad y despliegue (investigación)\n",
        "- Middleware de latencia y logger estructurado (añade header `X-Process-Time-ms`)\n",
        "- Manejo de warnings cuando la entrada está fuera de rango esperado\n",
        "- Dockerfile mínimo para empaquetar y correr localmente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf0a67ab",
      "metadata": {
        "id": "bf0a67ab"
      },
      "outputs": [],
      "source": [
        "# TODO (opcional): pega aquí snippets de middleware o Dockerfile que diseñes\n",
        "# class TimingMiddleware(...): ...\n",
        "# FROM python:3.11-slim\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60d5fcca",
      "metadata": {
        "id": "60d5fcca"
      },
      "source": [
        "\n",
        "---\n",
        "## 7) Criterios de evaluación (rúbrica breve)\n",
        "- **Justificación técnica (25%)**: dataset, métrica, modelo y preprocesamiento argumentados.\n",
        "- **Calidad del pipeline (20%)**: reproducibilidad y limpieza (Pipeline, persistencia correcta).\n",
        "- **Contrato y validaciones (25%)**: Pydantic coherente, errores claros, orden de features garantizado.\n",
        "- **Pruebas (20%)**: variedad de casos, evidencia de resultados y manejo de fallos.\n",
        "- **Código y documentación (10%)**: legibilidad, estructura y claridad de mensajes.\n",
        "\n",
        "---\n",
        "## Bitácora de decisiones (responde aquí)\n",
        "- Dataset y objetivo:\n",
        "- Selección de features/target:\n",
        "- Modelo y preprocesamiento:\n",
        "- Métrica principal y resultados:\n",
        "- Decisiones de contrato (payload, validaciones, respuestas):\n",
        "- Observabilidad y pruebas:\n",
        "- Lecciones aprendidas:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lab_u4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

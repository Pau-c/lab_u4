{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "99c51ec8",
      "metadata": {
        "id": "99c51ec8"
      },
      "source": [
        "\n",
        "# Taller (3h) — FastAPI + Scikit-Learn orientado a investigación\n",
        "**Objetivo:** Diseñar, entrenar y servir un modelo de ML **investigando** las decisiones técnicas clave.  \n",
        "**Entrega:** API funcional (FastAPI) + breve informe (markdown dentro del notebook) justificando decisiones.\n",
        "\n",
        "> Filosofía del taller: menos receta, más criterio. No hay una única respuesta correcta; lo evaluado es la **calidad del razonamiento**, la **limpieza de la implementación** y la **capacidad de probar** la API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdea1218",
      "metadata": {
        "id": "bdea1218"
      },
      "source": [
        "\n",
        "## Agenda sugerida (3h)\n",
        "1) **Planteo del problema y dataset** (30–40 min)  \n",
        "2) **Entrenamiento y persistencia** (40–50 min)  \n",
        "3) **Diseño del contrato y API** (45–55 min)  \n",
        "4) **Pruebas, errores y mejoras** (30–35 min)\n",
        "\n",
        "### Reglas\n",
        "- No borres los encabezados `TODO`. Agrega tu código debajo de cada bloque indicado.\n",
        "- Documenta tus decisiones en la sección **Bitácora** al final.\n",
        "- Puedes trabajar en equipo, pero cada entrega debe ser individual y original.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0cc07b6",
      "metadata": {
        "id": "e0cc07b6"
      },
      "source": [
        "\n",
        "---\n",
        "## 1) Selección de dataset y formulación del problema (investigación)\n",
        "Elige **uno**:\n",
        "- A) `sklearn.datasets.load_wine` (clasificación 3 clases, baseline rápido)\n",
        "- B) Un dataset tabular de UCI, Kaggle u otra fuente **citable** (debe ser pequeño/mediano y con licencia apta)\n",
        "- C) Un CSV propio (explica origen y variables)\n",
        "\n",
        "**Requisitos mínimos:**\n",
        "- Problema de **clasificación** o **regresión** tabular\n",
        "- Al menos **6 features numéricas** (puedes convertir categóricas)\n",
        "- Justifica por qué es un buen caso para servir vía API\n",
        "\n",
        "**Entrega (en esta celda, texto breve):** Describe el dataset, objetivo, variables y métrica principal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a51c33",
      "metadata": {
        "id": "15a51c33"
      },
      "source": [
        "\n",
        "### 1.1 Carga y exploración (TODO)\n",
        "- Carga el dataset (pd.read_csv o loader de sklearn).\n",
        "- Muestra `head()`, `describe()` y verifica nulos/outliers.\n",
        "- Selecciona `X` (features) y `y` (target); explica tu elección.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b92213bd",
      "metadata": {
        "id": "b92213bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- HEAD (Primeras 5 filas) ---\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "\n",
            "--- DESCRIBE (Estadísticas descriptivas) ---\n",
            "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
            "count         150.000000        150.000000         150.000000   \n",
            "mean            5.843333          3.057333           3.758000   \n",
            "std             0.828066          0.435866           1.765298   \n",
            "min             4.300000          2.000000           1.000000   \n",
            "25%             5.100000          2.800000           1.600000   \n",
            "50%             5.800000          3.000000           4.350000   \n",
            "75%             6.400000          3.300000           5.100000   \n",
            "max             7.900000          4.400000           6.900000   \n",
            "\n",
            "       petal width (cm)      target  \n",
            "count        150.000000  150.000000  \n",
            "mean           1.199333    1.000000  \n",
            "std            0.762238    0.819232  \n",
            "min            0.100000    0.000000  \n",
            "25%            0.300000    0.000000  \n",
            "50%            1.300000    1.000000  \n",
            "75%            1.800000    2.000000  \n",
            "max            2.500000    2.000000  \n",
            "\n",
            "--- NULOS (Conteo por columna) ---\n",
            "sepal length (cm)    0\n",
            "sepal width (cm)     0\n",
            "petal length (cm)    0\n",
            "petal width (cm)     0\n",
            "target               0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# TODO: Carga y EDA mínima\n",
        "import pandas as pd\n",
        "\n",
        "# from sklearn.datasets import load_wine\n",
        "\n",
        "# Ejemplo de estructura (reemplaza con tu fuente):\n",
        "# df = pd.read_csv(\"TU_DATASET.csv\")\n",
        "# ---- TU CÓDIGO AQUÍ ----\n",
        "\n",
        "# ---- DATASET DE PRUEBA- MODIFICAR ----\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris(as_frame=True)\n",
        "df = iris_data.frame\n",
        "\n",
        "#  Exploración\n",
        "print(\"--- HEAD (Primeras 5 filas) ---\")\n",
        "print(df.head())\n",
        "print(\"\\n--- DESCRIBE (Estadísticas descriptivas) ---\")\n",
        "print(df.describe())\n",
        "print(\"\\n--- NULOS (Conteo por columna) ---\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "575da8f8",
      "metadata": {
        "id": "575da8f8"
      },
      "source": [
        "\n",
        "---\n",
        "## 2) Entrenamiento y persistencia del modelo (investigación)\n",
        "Toma decisiones y **justifícalas**:\n",
        "- ¿Modelo base? (p. ej. `LogisticRegression`, `RandomForest`, `XGBoost` si lo instalas)\n",
        "- ¿Preprocesamiento? (escala, imputación, OneHot, etc.)\n",
        "- ¿Validación? (`train_test_split` vs `cross_val_score`)\n",
        "- ¿Métrica? (clasificación: accuracy/F1; regresión: RMSE/MAE…)\n",
        "\n",
        "**Requisito:** empaqueta tu flujo en un `Pipeline` de sklearn y **persiste** el modelo y columnas (joblib + JSON).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6172f286",
      "metadata": {
        "id": "6172f286"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Métricas de prueba: Accuracy = 0.9333\n"
          ]
        }
      ],
      "source": [
        "# TODO: split, pipeline, training, evaluación y persistencia\n",
        "from pathlib import Path\n",
        "import json, joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")\n",
        "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Variables esperadas:\n",
        "# X, y = ...\n",
        "# pipeline = ...\n",
        "# métricas calculadas en 'metrics' (dict)\n",
        "\n",
        "# ---- TU CÓDIGO AQUÍ ----\n",
        "\n",
        "# ---- DATASET DE PRUEBA- MODIFICAR ----\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# 3. Selección de X (features) y y (target)\n",
        "X = df.drop(columns=[\"target\"])  # quedan todas las columnas de medidas de la flor.\n",
        "# y (Target): La columna 'target' a predecir.\n",
        "y = df[\"target\"]\n",
        "\n",
        "# split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "# pipeline\n",
        "pipeline = Pipeline(\n",
        "    [(\"scaler\", StandardScaler()), (\"model\", KNeighborsClassifier(n_neighbors=5))]\n",
        ")\n",
        "\n",
        "# training\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# eval\n",
        "y_pred = pipeline.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# ---- DATASET DE PRUEBA- MODIFICAR END----\n",
        "\n",
        "#  diccionario de métricas\n",
        "metrics = {\n",
        "    \"test_accuracy\": round(test_accuracy, 4),\n",
        "    \"model_type\": \"KNeighborsClassifier\",\n",
        "    \"preprocessing\": \"StandardScaler\",\n",
        "}\n",
        "print(f\"\\nMétricas de prueba: Accuracy = {metrics['test_accuracy']}\")\n",
        "\n",
        "\n",
        "# TODO: Persistir\n",
        "# persiste modelo\n",
        "joblib.dump(pipeline, ARTIFACTS_DIR / \"model.joblib\")\n",
        "# persiste orden de cols\n",
        "json.dump(\n",
        "    {\"feature_columns\": list(X.columns)},\n",
        "    open(ARTIFACTS_DIR / \"feature_columns.json\", \"w\"),\n",
        ")\n",
        "# persiste metadatos y metricas\n",
        "json.dump({\"metrics\": metrics}, open(ARTIFACTS_DIR / \"metadata.json\", \"w\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c134dd",
      "metadata": {
        "id": "00c134dd"
      },
      "source": [
        "\n",
        "---\n",
        "## 3) Diseño del contrato de la API (investigación)\n",
        "Define **endpoints mínimos**:\n",
        "- `GET /health` (estado, versión del modelo, métrica)\n",
        "- `POST /predict` (un registro)\n",
        "- `POST /predict-batch` (lista de registros)\n",
        "\n",
        "**Decisiones a justificar:**\n",
        "- ¿Qué validaciones aplicas en `Pydantic`? (rango, tipos, campos extra)\n",
        "- ¿Cómo garantizas el **orden** de columnas?\n",
        "- ¿Qué devuelves además de la predicción? (probabilidades, latencia, advertencias)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "caf840dc",
      "metadata": {
        "id": "caf840dc"
      },
      "outputs": [],
      "source": [
        "# TODO: Generar un esquema dinámico a partir de las columnas persistidas (opcional pero recomendado)\n",
        "# Carga feature_columns.json y crea un dict para generar ejemplos de payload\n",
        "import json, os\n",
        "from pathlib import Path\n",
        "\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")\n",
        "feat_path = ARTIFACTS_DIR / \"feature_columns.json\"\n",
        "\n",
        "\n",
        "# ---- TU CÓDIGO AQUÍ ----\n",
        "# 1. Cargar la lista de columnas (el contrato de entrada)\n",
        "if not feat_path.exists():\n",
        "       raise FileNotFoundError(\n",
        "        f\"El archivo de columnas no existe en {feat_path}. Ejecuta la Sección 2 (entrenamiento) primero.\"\n",
        "    )\n",
        "\n",
        "with open(feat_path, 'r') as f:\n",
        "    column_data = json.load(f)\n",
        "\n",
        "# La lista de features en el orden de entrenamiento\n",
        "feature_columns = column_data.get(\"feature_columns\", [])\n",
        "\n",
        "# 2. Construye payload de ejemplo (para usar en pruebas)\n",
        "sample_payload = {}\n",
        "\n",
        "# Valores típicos de medidas del Iris están entre 4.0 y 8.0 cm\n",
        "EXAMPLE_VALUE = 5.5 \n",
        "for col in feature_columns:\n",
        "    sample_payload[col] = EXAMPLE_VALUE \n",
        "    \n",
        "# ---- FIN TU CÓDIGO AQUÍ ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8abce9f",
      "metadata": {
        "id": "f8abce9f"
      },
      "source": [
        "\n",
        "---\n",
        "## 4) Implementación de FastAPI (investigación)\n",
        "Crea un archivo `app.py` con:\n",
        "- Carga perezosa de `model.joblib` y `feature_columns.json`\n",
        "- Esquemas Pydantic (v2)\n",
        "- Endpoints `/health`, `/predict`, `/predict-batch`\n",
        "- Manejo de errores con `HTTPException` y mensajes claros\n",
        "\n",
        "**Pistas** (no copiar/pegar sin entender):\n",
        "- `model = joblib.load(...)`\n",
        "- `class Sample(BaseModel): ...`\n",
        "- `model.predict` y/o `model.predict_proba`\n",
        "- Retornar JSON con `dict | BaseModel`\n",
        "\n",
        "**Requisito:** esta celda **debe** escribir `app.py` con al menos la estructura básica.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c41fccc6",
      "metadata": {
        "id": "c41fccc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'app.py escrito (plantilla con TODOs)'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Escribir app.py\n",
        "from textwrap import dedent\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "app_code = dedent(\n",
        "    \"\"\"\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel, ConfigDict, Field\n",
        "from typing import List, Dict\n",
        "import joblib, json, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "APP_VERSION = \"0.1.0\"\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")\n",
        "MODEL_PATH = ARTIFACTS_DIR / \"model.joblib\"\n",
        "COLUMNS_PATH = ARTIFACTS_DIR / \"feature_columns.json\"\n",
        "META_PATH = ARTIFACTS_DIR / \"metadata.json\"\n",
        "\n",
        "app = FastAPI(title=\"ML API\", version=APP_VERSION)\n",
        "\n",
        "# Variables globales que se cargarán al inicio\n",
        "model = None\n",
        "columns = []\n",
        "meta = {}\n",
        "label_map = {0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"} #traduce la etiqueta en predicciones\n",
        "\n",
        "\n",
        "# TODO: Define tus modelos Pydantic aquí\n",
        "class Sample(BaseModel):\n",
        "    model_config = ConfigDict(extra=\"forbid\")\n",
        "    # ---- COMPLETA CON TUS CAMPOS SEGÚN feature_columns.json ----\n",
        "    \n",
        "    sepal_length_cm: float = Field(..., ge=3.0, le=8.5, description=\"Longitud del sépalo en cm\")\n",
        "    sepal_width_cm: float = Field(..., ge=1.5, le=5.0, description=\"Ancho del sépalo en cm\")\n",
        "    petal_length_cm: float = Field(..., ge=0.5, le=7.5, description=\"Longitud del pétalo en cm\")\n",
        "    petal_width_cm: float = Field(..., ge=0.0, le=3.0, description=\"Ancho del pétalo en cm\")\n",
        "\n",
        "\n",
        "class PredictionOut(BaseModel):\n",
        "    # ---- COMPLETA: qué devuelves? label / score / probs / latencia ----\n",
        "    label_id: int = Field(..., description=\"ID de la especie predicha (0, 1, 2).\")\n",
        "    label_name: str = Field(..., description=\"Nombre de la especie predicha (Setosa, Versicolor, Virginica).\")\n",
        "    score: float = Field(..., ge=0.0, le=1.0, description=\"Probabilidad o confianza de la predicción.\")\n",
        "    latency_ms: float = Field(..., gt=0, description=\"Tiempo de procesamiento de la predicción en milisegundos.\")\n",
        "    pass\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_artifacts():\n",
        "    global model, columns, meta\n",
        "    if not MODEL_PATH.exists():\n",
        "        raise RuntimeError(\"Modelo no encontrado. Entrena y exporta primero.\")\n",
        "    model = joblib.load(MODEL_PATH)\n",
        "    columns = json.loads(COLUMNS_PATH.read_text())[\"feature_columns\"]\n",
        "    meta = json.loads(META_PATH.read_text()) if META_PATH.exists() else {}\n",
        "\n",
        "\n",
        "def prepare_data_for_model(data_samples: List[Sample], columns: List[str]) -> np.ndarray:\n",
        "    # Convertir cada Sample a un diccionario\n",
        "    data_dicts = [sample.model_dump() for sample in data_samples]\n",
        "    \n",
        "    # Crear la matriz NumPy en el orden correcto\n",
        "    X_input = []\n",
        "    for d in data_dicts:\n",
        "        # Asegura que los valores se extraigan en el orden de 'columns'\n",
        "        row = [d[col] for col in columns]\n",
        "        X_input.append(row)\n",
        "        \n",
        "    return np.array(X_input)\n",
        "\n",
        "#ENDPOINTS \n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\n",
        "        \"status\": \"ok\",\n",
        "        \"version\": APP_VERSION,\n",
        "        \"metrics\": meta.get(\"metrics\"),\n",
        "        \"n_features\": len(columns),\n",
        "        \"model_pipeline_steps\": [name for name, _ in model.steps] if model else \"N/A\" #estructura interna del modelo\n",
        "        }\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(sample: Sample):\n",
        "    try:\n",
        "        start = time.perf_counter()\n",
        "        # TODO: transforma 'sample' a lista en el orden de 'columns'\n",
        "        # y haz model.predict / predict_proba\n",
        "        # ---- TU CÓDIGO AQUÍ ----\n",
        "        \n",
        "        X_input = prepare_data_for_model([sample], columns)\n",
        "        #   predicciones\n",
        "        prediction_id = model.predict(X_input)[0]\n",
        "        prediction_proba = model.predict_proba(X_input)[0]\n",
        "        \n",
        "        # Calcular la confianza \n",
        "        score = np.max(prediction_proba)\n",
        "        \n",
        "        # latencia y formatear salida\n",
        "        latency_ms = (time.perf_counter() - start) * 1000\n",
        "        \n",
        "        # con el mapa se obtiene el nombre de la etiqueta\n",
        "        label_name = label_map.get(prediction_id, \"Desconocida\")\n",
        "        \n",
        "        return PredictionOut(\n",
        "            label_id=int(prediction_id),\n",
        "            label_name=label_name,\n",
        "            score=round(score, 4),\n",
        "            latency_ms=round(latency_ms, 3)\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error en /predict: {e}\")\n",
        "        raise HTTPException(status_code=400, detail=f\"Error en el procesamiento de la predicción: {str(e)}\")\n",
        "\n",
        "\n",
        "@app.post(\"/predict-batch\")\n",
        "def predict_batch(samples: List[Sample]):\n",
        "    try:\n",
        "        # TODO: similar a /predict pero para lista\n",
        "        # ---- TU CÓDIGO AQUÍ ----\n",
        "        \n",
        "        start = time.perf_counter()\n",
        "        X_input = prepare_data_for_model(samples, columns)\n",
        "        \n",
        "        #  predicciones\n",
        "        prediction_ids = model.predict(X_input)\n",
        "        prediction_probas = model.predict_proba(X_input)\n",
        "        \n",
        "        results = []\n",
        "        for id_pred, probas in zip(prediction_ids, prediction_probas):\n",
        "            score = np.max(probas)\n",
        "            label_name = label_map.get(id_pred, \"Desconocida\")\n",
        "            \n",
        "            results.append(PredictionOut(\n",
        "                label_id=int(id_pred),\n",
        "                label_name=label_name,\n",
        "                score=round(score, 4),\n",
        "                latency_ms=0.0 # Se dejará en 0.0 para evitar complejidad en el batch\n",
        "            ))\n",
        "\n",
        "        # Reemplaza latency_ms individual con el tiempo total del batch\n",
        "        total_latency_ms = (time.perf_counter() - start) * 1000\n",
        "        \n",
        "        # Para el batch, se actualiza el primer elemento \n",
        "        if results:\n",
        "            results[0].latency_ms = round(total_latency_ms, 3)\n",
        "            \n",
        "        return results\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error en /predict-batch: {e}\")\n",
        "        raise HTTPException(status_code=400, detail=f\"Error en el procesamiento del lote: {str(e)}\")\n",
        "\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "Path(\"app.py\").write_text(app_code, encoding='utf-8')\n",
        "\"app.py escrito (plantilla con TODOs)\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3effd9b0",
      "metadata": {
        "id": "3effd9b0"
      },
      "source": [
        "\n",
        "### 4.1 Ejecutar el servidor\n",
        "```bash\n",
        "uvicorn app:app --reload --port 8000\n",
        "```\n",
        "Abre `http://127.0.0.1:8000/docs` y prueba manualmente. Registra resultados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59771f1d",
      "metadata": {
        "id": "59771f1d"
      },
      "source": [
        "\n",
        "---\n",
        "## 5) Pruebas y casos límite (investigación)\n",
        "Define y ejecuta **al menos 6** pruebas:\n",
        "- 3 válidas (predict y batch)\n",
        "- 3 inválidas (campo faltante, tipo incorrecto, campo extra, etc.)\n",
        "\n",
        "Incluye código de prueba y captura de respuestas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc5c4f6",
      "metadata": {
        "id": "cbc5c4f6"
      },
      "outputs": [],
      "source": [
        "# TODO: pruebas con requests (server debe estar corriendo)\n",
        "# import requests, json\n",
        "# payload_valido = {...}\n",
        "# r = requests.post(\"http://127.0.0.1:8000/predict\", json=payload_valido, timeout=5)\n",
        "# print(r.status_code, r.json())\n",
        "raise NotImplementedError(\"Escribe tus pruebas de cliente aquí\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "662bd072",
      "metadata": {
        "id": "662bd072"
      },
      "source": [
        "\n",
        "---\n",
        "## 6) (Opcional) Observabilidad y despliegue (investigación)\n",
        "- Middleware de latencia y logger estructurado (añade header `X-Process-Time-ms`)\n",
        "- Manejo de warnings cuando la entrada está fuera de rango esperado\n",
        "- Dockerfile mínimo para empaquetar y correr localmente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf0a67ab",
      "metadata": {
        "id": "bf0a67ab"
      },
      "outputs": [],
      "source": [
        "# TODO (opcional): pega aquí snippets de middleware o Dockerfile que diseñes\n",
        "# class TimingMiddleware(...): ...\n",
        "# FROM python:3.11-slim\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60d5fcca",
      "metadata": {
        "id": "60d5fcca"
      },
      "source": [
        "\n",
        "---\n",
        "## 7) Criterios de evaluación (rúbrica breve)\n",
        "- **Justificación técnica (25%)**: dataset, métrica, modelo y preprocesamiento argumentados.\n",
        "- **Calidad del pipeline (20%)**: reproducibilidad y limpieza (Pipeline, persistencia correcta).\n",
        "- **Contrato y validaciones (25%)**: Pydantic coherente, errores claros, orden de features garantizado.\n",
        "- **Pruebas (20%)**: variedad de casos, evidencia de resultados y manejo de fallos.\n",
        "- **Código y documentación (10%)**: legibilidad, estructura y claridad de mensajes.\n",
        "\n",
        "---\n",
        "## Bitácora de decisiones (responde aquí)\n",
        "- Dataset y objetivo:\n",
        "- Selección de features/target:\n",
        "- Modelo y preprocesamiento:\n",
        "- Métrica principal y resultados:\n",
        "- Decisiones de contrato (payload, validaciones, respuestas):\n",
        "- Observabilidad y pruebas:\n",
        "- Lecciones aprendidas:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lab_u4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
